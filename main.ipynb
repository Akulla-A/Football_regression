{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project is about the price of a football player.\n",
    "Since a price is a integer, without an obvious classification, we can suppose that we are in a regression task.\n",
    "\n",
    "To achieve this regression task, we have 3 datasets, Player statistics, Player price and club statistics, club ranking, that we can use afterward to predict the price of a player.\n",
    "Something we need to keep in mind is that we only have clubs and stats. However, others factors like the hype around a player or the attitude towards his teammates/dramas are not easy parameters to quantify, we can't calculate it but it has an obvious impact on the price. This factor + prices that has a big ranges ( dozens of millions ), makes it impossible to reach a perfect prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "\n",
    "\n",
    "from os import listdir, environ\n",
    "from os.path import isfile, join\n",
    "\n",
    "from rapidfuzz import process\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import t\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config InlineBackend.figure_format=\"retina\"\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['clubs', 'club_games', 'game_lineups', 'players', 'Soccer_Football Clubs Ranking', 'stats'])\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "\n",
    "path = \"data/\"\n",
    "for f in listdir(path):\n",
    "    if isfile(join(path, f)):\n",
    "        datasets[f.replace(\".csv\", \"\")] = pd.read_csv(join(path, f))\n",
    "\n",
    "print(datasets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed some datasets from the kaggle dataset. Since some of them are redundant or useless, as such, we have the \"player_valuations\" with the price of the player, something we can get from players.csv. So, we don't need to keep extra datasets.\n",
    "We only modify/delete datasets in the transfertmarket dataset, we only keep players, game_lineups,clubs and club_games from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear columns\n",
    "clear_columns = {\n",
    "    \"players\": {\n",
    "        \"first_name\",\n",
    "        \"last_name\",\n",
    "        \"player_code\",\n",
    "        \"city_of_birth\",\n",
    "        \"country_of_citizenship\",\n",
    "        \"image_url\",\n",
    "        \"url\"\n",
    "    },\n",
    "\n",
    "    \"stats\": {\n",
    "        \"Rk\", \"Born\", \n",
    "    }\n",
    "}\n",
    "\n",
    "# Clear too old data, we keep 2023 ones.\n",
    "# The issue is that, we have valuations for each year. Something we don't want.\n",
    "\n",
    "# Some names are in double in stats.csv, keep the newer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to merge \"Players.csv\" and \"Stats.csv\" into 1 dataset.\n",
    "\n",
    "About the other datasets:\n",
    "- We can get the win ratio in club_games\n",
    "- How many time the player was a team captain and if he was in the starting team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lups = datasets[\"game_lineups\"]\n",
    "all_players = lups['player_id'].unique()\n",
    "\n",
    "# captains\n",
    "team_captain_games = lups[lups['team_captain'] == 1]\n",
    "captain_counts = team_captain_games['player_id'].value_counts()\n",
    "captain_counts = captain_counts.reindex(all_players, fill_value=0)\n",
    "\n",
    "# starting\n",
    "starting_lineups = lups[lups['type'] == \"starting_lineup\"]\n",
    "starting_counts = starting_lineups['player_id'].value_counts()\n",
    "starting_counts = starting_counts.reindex(all_players, fill_value=0)\n",
    "\n",
    "# substitutes\n",
    "substitutes = lups[lups['type'] == \"substitutes\"]\n",
    "substitutes_counts = substitutes['player_id'].value_counts()\n",
    "substitutes_counts = substitutes_counts.reindex(all_players, fill_value=0)\n",
    "\n",
    "# Rename\n",
    "substitutes_counts.columns = ['player_id', 'substitutes_number']\n",
    "starting_counts.columns = ['player_id', 'starting_lineup_number']\n",
    "captain_counts.columns = ['player_id', 'captain_number']\n",
    "\n",
    "starting_counts = starting_counts.reset_index()\n",
    "substitutes_counts = substitutes_counts.reset_index()\n",
    "captain_counts = captain_counts.reset_index()\n",
    "\n",
    "starting_counts = starting_counts.rename(columns={\"count\": \"starting_count\"})\n",
    "substitutes_counts = substitutes_counts.rename(columns={\"count\": \"substitutes_counts\"})\n",
    "captain_counts = captain_counts.rename(columns={\"count\": \"captain_counts\"})\n",
    "\n",
    "# Merge the clean_dataset with counts DataFrames\n",
    "_datasetCleaning = pd.merge(datasets[\"stats\"], datasets[\"players\"], on=\"name\")\n",
    "_datasetCleaning = pd.merge(_datasetCleaning, substitutes_counts, on=\"player_id\", how=\"left\")\n",
    "_datasetCleaning = pd.merge(_datasetCleaning, starting_counts, on=\"player_id\", how=\"left\")\n",
    "_datasetCleaning = pd.merge(_datasetCleaning, captain_counts, on=\"player_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>name</th>\n",
       "      <th>Nation</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Age</th>\n",
       "      <th>Born</th>\n",
       "      <th>MP</th>\n",
       "      <th>Starts</th>\n",
       "      <th>...</th>\n",
       "      <th>highest_market_value_in_eur</th>\n",
       "      <th>contract_expiration_date</th>\n",
       "      <th>agent_name</th>\n",
       "      <th>image_url</th>\n",
       "      <th>url</th>\n",
       "      <th>current_club_domestic_competition_id</th>\n",
       "      <th>current_club_name</th>\n",
       "      <th>index_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Brenden Aaronson</td>\n",
       "      <td>USA</td>\n",
       "      <td>MFFW</td>\n",
       "      <td>Leeds United</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>22</td>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>2024-06-30 00:00:00</td>\n",
       "      <td>Wasserman</td>\n",
       "      <td>https://img.a.transfermarkt.technology/portrai...</td>\n",
       "      <td>https://www.transfermarkt.co.uk/brenden-aarons...</td>\n",
       "      <td>L1</td>\n",
       "      <td>1.FC Union Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Yunis Abdelhamid</td>\n",
       "      <td>MAR</td>\n",
       "      <td>DF</td>\n",
       "      <td>Reims</td>\n",
       "      <td>Ligue 1</td>\n",
       "      <td>35</td>\n",
       "      <td>1987</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>2024-06-30 00:00:00</td>\n",
       "      <td>PSC</td>\n",
       "      <td>https://img.a.transfermarkt.technology/portrai...</td>\n",
       "      <td>https://www.transfermarkt.co.uk/yunis-abdelham...</td>\n",
       "      <td>FR1</td>\n",
       "      <td>Stade Reims</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Himad Abdelli</td>\n",
       "      <td>FRA</td>\n",
       "      <td>MFFW</td>\n",
       "      <td>Angers</td>\n",
       "      <td>Ligue 1</td>\n",
       "      <td>23</td>\n",
       "      <td>1999</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>2026-06-30 00:00:00</td>\n",
       "      <td>CNS</td>\n",
       "      <td>https://img.a.transfermarkt.technology/portrai...</td>\n",
       "      <td>https://www.transfermarkt.co.uk/himad-abdelli/...</td>\n",
       "      <td>FR1</td>\n",
       "      <td>Angers SCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Salis Abdul Samed</td>\n",
       "      <td>GHA</td>\n",
       "      <td>MF</td>\n",
       "      <td>Lens</td>\n",
       "      <td>Ligue 1</td>\n",
       "      <td>22</td>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>2028-06-30 00:00:00</td>\n",
       "      <td>BLACKSKILL</td>\n",
       "      <td>https://img.a.transfermarkt.technology/portrai...</td>\n",
       "      <td>https://www.transfermarkt.co.uk/salis-abdul-sa...</td>\n",
       "      <td>FR1</td>\n",
       "      <td>RC Lens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Laurent Abergel</td>\n",
       "      <td>FRA</td>\n",
       "      <td>MF</td>\n",
       "      <td>Lorient</td>\n",
       "      <td>Ligue 1</td>\n",
       "      <td>30</td>\n",
       "      <td>1993</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>2026-06-30 00:00:00</td>\n",
       "      <td>N.Agency</td>\n",
       "      <td>https://img.a.transfermarkt.technology/portrai...</td>\n",
       "      <td>https://www.transfermarkt.co.uk/laurent-aberge...</td>\n",
       "      <td>FR1</td>\n",
       "      <td>FC Lorient</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rk               name Nation   Pos         Squad            Comp  Age  \\\n",
       "0   1   Brenden Aaronson    USA  MFFW  Leeds United  Premier League   22   \n",
       "1   2   Yunis Abdelhamid    MAR    DF         Reims         Ligue 1   35   \n",
       "2   3      Himad Abdelli    FRA  MFFW        Angers         Ligue 1   23   \n",
       "3   4  Salis Abdul Samed    GHA    MF          Lens         Ligue 1   22   \n",
       "4   5    Laurent Abergel    FRA    MF       Lorient         Ligue 1   30   \n",
       "\n",
       "   Born  MP  Starts  ...  highest_market_value_in_eur  \\\n",
       "0  2000  20      19  ...                   30000000.0   \n",
       "1  1987  22      22  ...                    2500000.0   \n",
       "2  1999  14       8  ...                    2500000.0   \n",
       "3  2000  20      20  ...                   18000000.0   \n",
       "4  1993  15      15  ...                    3000000.0   \n",
       "\n",
       "   contract_expiration_date  agent_name  \\\n",
       "0       2024-06-30 00:00:00   Wasserman   \n",
       "1       2024-06-30 00:00:00         PSC   \n",
       "2       2026-06-30 00:00:00         CNS   \n",
       "3       2028-06-30 00:00:00  BLACKSKILL   \n",
       "4       2026-06-30 00:00:00    N.Agency   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://img.a.transfermarkt.technology/portrai...   \n",
       "1  https://img.a.transfermarkt.technology/portrai...   \n",
       "2  https://img.a.transfermarkt.technology/portrai...   \n",
       "3  https://img.a.transfermarkt.technology/portrai...   \n",
       "4  https://img.a.transfermarkt.technology/portrai...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.transfermarkt.co.uk/brenden-aarons...   \n",
       "1  https://www.transfermarkt.co.uk/yunis-abdelham...   \n",
       "2  https://www.transfermarkt.co.uk/himad-abdelli/...   \n",
       "3  https://www.transfermarkt.co.uk/salis-abdul-sa...   \n",
       "4  https://www.transfermarkt.co.uk/laurent-aberge...   \n",
       "\n",
       "   current_club_domestic_competition_id  current_club_name  index_x  index_y  \\\n",
       "0                                    L1  1.FC Union Berlin      NaN      NaN   \n",
       "1                                   FR1        Stade Reims      NaN      NaN   \n",
       "2                                   FR1         Angers SCO      NaN      NaN   \n",
       "3                                   FR1            RC Lens      NaN      NaN   \n",
       "4                                   FR1         FC Lorient      NaN      NaN   \n",
       "\n",
       "   index  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_datasetCleaning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1933, 149)\n"
     ]
    }
   ],
   "source": [
    "print(_datasetCleaning.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting squad column into club ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the squad column is a categorical value with many possible outcomes, performing one-hot encoding on it would produce a big amount of columns (one for each team).\n",
    "\n",
    "We know there should be a correlation between the club a player belongs to and a player's market value. Since good teams usually have good players, so more valuable ones. Therefore, we would like to keep some information about the team. \n",
    "\n",
    "In order to solve this problem, we use another dataset in which we have several football teams and their latest rankings, and we try to replace the club names with their rankings.\n",
    "\n",
    "The first problem we encounter is that the clubs in our original dataset might be refered to with slightly different names than in the new dataset we're trying to use, since we got it from a different source, for example, 'Machester United' could be referred to as 'Man United'.\n",
    "\n",
    "To resolve this, we use fuzzy matching to find, for each player’s club, the closest matching club name in the rankings dataset. Once the matches are established, we replace the club names in the original dataset with their corresponding rankings. This method works because the club names in both datasets are very similar and differ only by minor variations, such as spelling or abbreviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we notice that all the players we have in the original dataset play in the top five leagues, therefore we restrict the rankings dataset to teams from five countries (England, Spain, Germany, Italy and France). This is especially useful because some teams have the same name. For example, 'Real Sociedad' is both present in Spain and Uruguay. But we make sure that there are no teams with the same name from the rankings dataset in these five countries. This way we make sure the matching is done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Players outside of the top 5 leagues in our dataset\n",
    "s = 0\n",
    "top5_leagues = ['Premier League', 'La Liga', 'Ligue 1', 'Bundesliga', 'Serie A']\n",
    "indexes = []\n",
    "n_rows = np.shape(_datasetCleaning)[0]\n",
    "for i in range(n_rows):\n",
    "    if _datasetCleaning.loc[i, 'Comp'] not in top5_leagues:\n",
    "        s += 1\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no players out of the top five leagues, we can proceed with restricting the rankings dataset on the five countries mentioned previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>club name</th>\n",
       "      <th>country</th>\n",
       "      <th>point score</th>\n",
       "      <th>1 year change</th>\n",
       "      <th>previous point scored</th>\n",
       "      <th>symbol change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88</td>\n",
       "      <td>1. FC Köln</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1633</td>\n",
       "      <td>105</td>\n",
       "      <td>1545</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>1. FC Union Berlin</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1655</td>\n",
       "      <td>5</td>\n",
       "      <td>1654</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>AC Milan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1850</td>\n",
       "      <td>21</td>\n",
       "      <td>1741</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>270</td>\n",
       "      <td>AFC Bournemouth</td>\n",
       "      <td>England</td>\n",
       "      <td>1512</td>\n",
       "      <td>7</td>\n",
       "      <td>1512</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>823</td>\n",
       "      <td>Ajaccio</td>\n",
       "      <td>France</td>\n",
       "      <td>1369</td>\n",
       "      <td>13</td>\n",
       "      <td>1369</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ranking          club name   country  point score  1 year change  \\\n",
       "0        88          1. FC Köln  Germany         1633            105   \n",
       "1        74  1. FC Union Berlin  Germany         1655              5   \n",
       "20       11            AC Milan    Italy         1850             21   \n",
       "54      270     AFC Bournemouth  England         1512              7   \n",
       "70      823             Ajaccio   France         1369             13   \n",
       "\n",
       "    previous point scored symbol change  \n",
       "0                    1545             +  \n",
       "1                    1654             +  \n",
       "20                   1741             +  \n",
       "54                   1512             -  \n",
       "70                   1369             -  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings_df = pd.read_csv(path + 'Soccer_Football Clubs Ranking.csv', sep=';')\n",
    "\n",
    "# We only keep teams in the big 5 leagues\n",
    "rankings_df = rankings_df[rankings_df['country'].isin(['Germany', 'Spain', 'France', 'Italy', 'England'])]\n",
    "rankings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check for duplicates in the rankings dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 unique duplicate values and 6 total duplicates in the column 'club name '.\n",
      "Duplicate values and their counts:\n",
      "Angers           1\n",
      "Evian TG         1\n",
      "GFC Ajaccio      1\n",
      "Málaga           1\n",
      "Middlesbrough    1\n",
      "Nancy            1\n",
      "Name: club name , dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate teams\n",
    "duplicates = rankings_df['club name '][rankings_df['club name '].duplicated()]\n",
    "\n",
    "if not duplicates.empty:\n",
    "    print(f\"There are {duplicates.nunique()} unique duplicate values and {duplicates.size} total duplicates in the column 'club name '.\")\n",
    "    print(\"Duplicate values and their counts:\")\n",
    "    print(duplicates.value_counts())\n",
    "else:\n",
    "    print(f\"There are no duplicates in the column 'club name '.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>club name</th>\n",
       "      <th>country</th>\n",
       "      <th>point score</th>\n",
       "      <th>1 year change</th>\n",
       "      <th>previous point scored</th>\n",
       "      <th>symbol change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>475</td>\n",
       "      <td>Angers</td>\n",
       "      <td>France</td>\n",
       "      <td>1440</td>\n",
       "      <td>121</td>\n",
       "      <td>1474</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>475</td>\n",
       "      <td>Angers</td>\n",
       "      <td>France</td>\n",
       "      <td>1440</td>\n",
       "      <td>121</td>\n",
       "      <td>1474</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>484</td>\n",
       "      <td>Evian TG</td>\n",
       "      <td>France</td>\n",
       "      <td>1439</td>\n",
       "      <td>2</td>\n",
       "      <td>1439</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>484</td>\n",
       "      <td>Evian TG</td>\n",
       "      <td>France</td>\n",
       "      <td>1439</td>\n",
       "      <td>2</td>\n",
       "      <td>1439</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>485</td>\n",
       "      <td>GFC Ajaccio</td>\n",
       "      <td>France</td>\n",
       "      <td>1438</td>\n",
       "      <td>1</td>\n",
       "      <td>1438</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>485</td>\n",
       "      <td>GFC Ajaccio</td>\n",
       "      <td>France</td>\n",
       "      <td>1438</td>\n",
       "      <td>1</td>\n",
       "      <td>1438</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>451</td>\n",
       "      <td>Málaga</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1446</td>\n",
       "      <td>1</td>\n",
       "      <td>1446</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>451</td>\n",
       "      <td>Málaga</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1446</td>\n",
       "      <td>1</td>\n",
       "      <td>1446</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>465</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>England</td>\n",
       "      <td>1443</td>\n",
       "      <td>4</td>\n",
       "      <td>1443</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>465</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>England</td>\n",
       "      <td>1443</td>\n",
       "      <td>4</td>\n",
       "      <td>1443</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>482</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>France</td>\n",
       "      <td>1439</td>\n",
       "      <td>2</td>\n",
       "      <td>1439</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>482</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>France</td>\n",
       "      <td>1439</td>\n",
       "      <td>2</td>\n",
       "      <td>1439</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ranking     club name   country  point score  1 year change  \\\n",
       "223       475         Angers   France         1440            121   \n",
       "224       475         Angers   France         1440            121   \n",
       "913       484       Evian TG   France         1439              2   \n",
       "914       484       Evian TG   France         1439              2   \n",
       "1165      485    GFC Ajaccio   France         1438              1   \n",
       "1166      485    GFC Ajaccio   France         1438              1   \n",
       "1628      451         Málaga    Spain         1446              1   \n",
       "1629      451         Málaga    Spain         1446              1   \n",
       "1691      465  Middlesbrough  England         1443              4   \n",
       "1692      465  Middlesbrough  England         1443              4   \n",
       "1781      482          Nancy   France         1439              2   \n",
       "1782      482          Nancy   France         1439              2   \n",
       "\n",
       "      previous point scored symbol change  \n",
       "223                    1474             -  \n",
       "224                    1474             -  \n",
       "913                    1439             -  \n",
       "914                    1439             -  \n",
       "1165                   1438             -  \n",
       "1166                   1438             -  \n",
       "1628                   1446             -  \n",
       "1629                   1446             -  \n",
       "1691                   1443             -  \n",
       "1692                   1443             -  \n",
       "1781                   1439             -  \n",
       "1782                   1439             -  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows = rankings_df[rankings_df['club name '].duplicated(keep=False)]\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the rows don't refer to different teams, so we can delete the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicates in the column 'club name '.\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows based on the column 'club name '\n",
    "rankings_df = rankings_df.drop_duplicates(subset='club name ', keep='first')\n",
    "duplicates = rankings_df['club name '][rankings_df['club name '].duplicated()]\n",
    "\n",
    "if not duplicates.empty:\n",
    "    print(f\"There are {duplicates.nunique()} unique duplicate values and {duplicates.size} total duplicates in the column 'club name '.\")\n",
    "    print(\"Duplicate values and their counts:\")\n",
    "    print(duplicates.value_counts())\n",
    "else:\n",
    "    print(f\"There are no duplicates in the column 'club name '.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can proceed with our matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of matches\n",
    "club_list = rankings_df['club name '].tolist()\n",
    "club_rankings = rankings_df.set_index('club name ')['ranking'].to_dict()\n",
    "\n",
    "def get_best_match(club_name):\n",
    "    match, score, _ = process.extractOne(club_name, club_list)\n",
    "    if score >= 50: \n",
    "        return club_rankings[match]\n",
    "    return None\n",
    "\n",
    "# Apply the function to all rows\n",
    "_datasetCleaning['Squad'] = _datasetCleaning['Squad'].apply(get_best_match)\n",
    "_datasetCleaning.rename(columns={'Squad': 'Club Ranking'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The football clubs are replaced with their corresponding rankings. We can proceed with the data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - One-Hot encoding/String transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original dataset, the foot side of players are plain text, with 2 possibles values, \"Right\" and \"Left\". Obviously, we can transform this attribute to 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_datasetCleaning[\"foot\"] = [int(x == \"right\") for x in _datasetCleaning[\"foot\"]]\n",
    "_datasetCleaning = pd.concat([_datasetCleaning, pd.get_dummies(_datasetCleaning.sub_position)], axis=1)\n",
    "_datasetCleaning = pd.concat([_datasetCleaning, pd.get_dummies(_datasetCleaning.Comp)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Converting Columns to Numericals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert boolean columns to 0s and 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean columns converted to 0s and 1s.\n"
     ]
    }
   ],
   "source": [
    "bool_columns = _datasetCleaning.select_dtypes(include=['bool']).columns\n",
    "for col in bool_columns:\n",
    "    _datasetCleaning[col] = _datasetCleaning[col].astype(int)\n",
    "\n",
    "print(\"Boolean columns converted to 0s and 1s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop non-numeric and useless columns that we don't need from our dataset.\n",
    "\n",
    "For every drop, there the reason:\n",
    "- \"Rk\", \"name\", \"Nation\", \"first_name\", \"last_name\", \"player_code\", \"city_of_birth\", \"date_of_birth\", \"contract_expiration_date\", \"agent_name\", \"image_url\", \n",
    "    'current_club_domestic_competition_id', \"url\": Not useful, there no specific values we can get from it.\n",
    "- \"country_of_birth\", \"country_of_citizenship\", \"current_club_name\". These values may be useful, however, there is +100 unique values, with 2000 rows, this could bring issues with outliers making no sense. An example would be someone in a \"unknown\" country, models could think this is important for the price of the player and the prices of players coming from the same country is correlated.\n",
    "- \"sub_position\", \"position\", \"Comp\". We one-hot encoded them, so we drop the string representation of these columns.\n",
    "- Pos. We already have this value under another name.\n",
    "- Born. We have the age of the player, something closer to 0 than born, and these 2 values gives roughly the same \"idea\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify non-numeric columns in the dataset\n",
    "post_process_drops = [\n",
    "    \"Rk\", \"name\", \"Nation\", \"first_name\", \"last_name\", \"player_code\", \"city_of_birth\", \"date_of_birth\", \"contract_expiration_date\", \"agent_name\", \"image_url\", \"player_id\", \"current_club_id\", \"last_season\",\n",
    "    'current_club_domestic_competition_id', \"url\", # Not useful.\n",
    "    \"country_of_birth\", \"country_of_citizenship\", # 102 unique values, we can't one-hot encode it else it would most likely make no sense for the regression.\n",
    "    \"sub_position\", \"position\", \"Comp\", # one-hot encoding\n",
    "    \"current_club_name\", # 198 unique values, same reason as the \"country_of_birth\"\n",
    "    \"Pos\", # We already have a attribute about the position of the player.\n",
    "    \"Born\" # The year in which a player is equivalent the age so we remove it. We already have it.\n",
    "]\n",
    "\n",
    "_datasetCleaning = _datasetCleaning.drop(post_process_drops, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if there are any non-numeric variables left. Since it would block most of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No non-numeric columns found.\n"
     ]
    }
   ],
   "source": [
    "# Check for non-numeric columns\n",
    "non_numeric_columns = _datasetCleaning.select_dtypes(exclude=['number'])\n",
    "if not non_numeric_columns.empty:\n",
    "    print(\"Non-numeric columns and their types:\")\n",
    "    for col in non_numeric_columns.columns:\n",
    "        print(f\"{col}: {non_numeric_columns[col].dtype}\")\n",
    "else:\n",
    "    print(\"No non-numeric columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove columns having only null values (if they exist), and each row containing a null value.\n",
    "Some columns are filled with null values, removing rows first would delete every values.\n",
    "We delete na-filled columns first, and we delete null rows next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We removed 3 columns.\n",
      "We removed 58 rows.\n"
     ]
    }
   ],
   "source": [
    "# Cleaning null values\n",
    "columnsSizePreNA = _datasetCleaning.shape[1]\n",
    "_datasetCleaning.dropna(how='all', axis=1, inplace=True) # We remove useless columns\n",
    "print(\"We removed \" + str(columnsSizePreNA - _datasetCleaning.shape[1]) + \" columns.\")\n",
    "\n",
    "columnsSizePreNA = _datasetCleaning.shape[0]\n",
    "_datasetCleaning.dropna(how='any', axis=0, inplace=True) # We remove null values\n",
    "print(\"We removed \" + str(columnsSizePreNA - _datasetCleaning.shape[0]) + \" rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Exploratory Data Analysis and Further Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Correlations Between Independent Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check for pairs of independent variables that are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated feature pairs:\n",
      "     Feature 1   Feature 2  Correlation\n",
      "13   PasTotAtt      PasAtt     1.000000\n",
      "38      TklWon        TklW     1.000000\n",
      "9    PasTotCmp      PasCmp     1.000000\n",
      "34      PasCrs         Crs     1.000000\n",
      "40     Touches     TouLive     0.999996\n",
      "4          Min         90s     0.999991\n",
      "2       Starts         Min     0.991605\n",
      "3       Starts         90s     0.991590\n",
      "23   PasShoCmp   PasShoAtt     0.983349\n",
      "24   PasMedCmp   PasMedAtt     0.982266\n",
      "14   PasTotAtt     PasLive     0.977309\n",
      "25      PasAtt     PasLive     0.977309\n",
      "26      PasAtt      PasCmp     0.972227\n",
      "15   PasTotAtt      PasCmp     0.972227\n",
      "7    PasTotCmp      PasAtt     0.972227\n",
      "5    PasTotCmp   PasTotAtt     0.972227\n",
      "8    PasTotCmp     PasLive     0.972029\n",
      "29     PasLive      PasCmp     0.972029\n",
      "17   PasTotAtt     TouLive     0.966592\n",
      "28      PasAtt     TouLive     0.966592\n",
      "16   PasTotAtt     Touches     0.966581\n",
      "27      PasAtt     Touches     0.966581\n",
      "30     PasLive     Touches     0.955986\n",
      "31     PasLive     TouLive     0.955978\n",
      "6    PasTotCmp  PasTotDist     0.939823\n",
      "22  PasTotDist      PasCmp     0.939823\n",
      "36      PasCmp     TouLive     0.932289\n",
      "11   PasTotCmp     TouLive     0.932289\n",
      "10   PasTotCmp     Touches     0.932266\n",
      "35      PasCmp     Touches     0.932266\n",
      "33     PasLive         Rec     0.930259\n",
      "43     Carries         Rec     0.925631\n",
      "18  PasTotDist   PasMedCmp     0.923587\n",
      "39      Blocks     BlkPass     0.920174\n",
      "20  PasTotDist      PasAtt     0.918789\n",
      "12   PasTotAtt  PasTotDist     0.918789\n",
      "37         Tkl     Tkl+Int     0.913144\n",
      "44  CarTotDist  CarPrgDist     0.910957\n",
      "19  PasTotDist   PasMedAtt     0.907828\n",
      "41     Touches         Rec     0.907661\n",
      "42     TouLive         Rec     0.907485\n",
      "0           MP         Min     0.905993\n",
      "1           MP         90s     0.905983\n",
      "21  PasTotDist     PasLive     0.901095\n",
      "32     PasLive     Carries     0.900038\n"
     ]
    }
   ],
   "source": [
    "correlations = _datasetCleaning.corr()\n",
    "np.fill_diagonal(correlations.values, np.nan) \n",
    "\n",
    "high_corr_pairs = []\n",
    "corr_dict = correlations.to_dict()\n",
    "d_columns = list(corr_dict.keys())\n",
    "\n",
    "for i in range(len(d_columns)):\n",
    "    for j in range(i + 1, len(d_columns)):\n",
    "        corr_value = corr_dict[d_columns[i]][d_columns[j]] \n",
    "        if abs(corr_value) > 0.9:\n",
    "            high_corr_pairs.append({\n",
    "                \"Feature 1\": d_columns[i],\n",
    "                \"Feature 2\": d_columns[j],\n",
    "                \"Correlation\": corr_value\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs)\n",
    "    high_corr_df.sort_values(by=\"Correlation\", ascending=False, inplace=True)  # Sort by correlation\n",
    "    print(\"Highly correlated feature pairs:\")\n",
    "    print(high_corr_df)\n",
    "else:\n",
    "    print(\"No highly correlated feature pairs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that some pairs of independent variables have very high correlation, so there is multicollinearity. Some of them reaching one in absolute value, which means some features might carry redundant information. For example 'Min' represents the number of minutes played by a player. and '90s' represents how many 90 minutes were played (matches), and the two are linked by the following relationship $\\text{90s} = \\frac{\\text{Min}}{90}$. \n",
    "\n",
    "So by keeping the two variables we store some redudant information. This can negatively impact certain machine learning models, especially linear models or those sensitive to feature scaling and relationships (e.g., Logistic Regression, Linear Regression) where coefficients become unreliable due to the inability to distinguish the impact of correlated variables. \n",
    "\n",
    "Therefore, we proceed by removing some of the independent variable that have high correlations. We focus on the ones that have the most high correlations, for example 'PasTotAtt' has very high correlations with six other independent variables, so we remove it.\n",
    "\n",
    "Based on the correlation values, we identify the following columns to remove: \"Starts\", \"90s\", \"Rec\", \"PasTotCmp\", \"PasTotAtt\", \"PasTotDist\", \"PasShoCmp\", \"PasMedCmp\", \"PasAtt\", \"PasLive\", \"PasCrs\", \"TklW\", \"Touches\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process_drops = [\n",
    "    \"Starts\", \"90s\", \"Rec\", \"PasTotCmp\", \"PasTotAtt\", \"PasTotDist\", \"PasShoCmp\", \"PasMedCmp\", \"PasAtt\", \"PasLive\", \"PasCrs\", \"TklW\", \"Touches\"\n",
    "]\n",
    "\n",
    "_datasetCleaning = _datasetCleaning.drop(post_process_drops, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Correlations With the Target Variable and Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the correlations with the target variable, and we check for the highest correlations in absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with high correlation to the target variable:\n",
      "                       Feature  Correlation\n",
      "0  highest_market_value_in_eur     0.778338\n",
      "1                        Goals     0.435240\n",
      "2                          Min     0.327651\n",
      "3                           MP     0.291847\n",
      "4               Premier League     0.272957\n",
      "5                 Club Ranking    -0.268297\n"
     ]
    }
   ],
   "source": [
    "target = 'market_value_in_eur'\n",
    "correlations = _datasetCleaning.corr()\n",
    "corr_with_target = correlations[target].drop(target)\n",
    "high_corr = corr_with_target[abs(corr_with_target) > 0.25].sort_values(ascending=False)\n",
    "\n",
    "\n",
    "if not high_corr.empty:\n",
    "    high_corr_df = high_corr.reset_index()\n",
    "    high_corr_df.columns = [\"Feature\", \"Correlation\"]\n",
    "    print(\"Features with high correlation to the target variable:\")\n",
    "    print(high_corr_df)\n",
    "else:\n",
    "    print(\"No features found with correlation > 0.25 to the target variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'Club Ranking': The correlation is negative because higher club rankings (closer to 1, so better teams) are associated with more valuable players. However, this does not mean that every player belonging to a top team has a high market value. For example, substitutes are usually not as good as the players in the starting eleven. As a result, the negative correlation between club ranking and market value exists but is not very strong in absolute value.\n",
    "\n",
    "- 'Min': The correlation is positive, as players with more minutes on the field are more likely to be skilled and stand out, leading to higher market value. However, this is not always the case. In lower-ranked teams, less valuable players often get more minutes due to a lack of better options. Additionally, some highly valuable players in top teams might spend more time on the bench, and injuries can also reduce minutes for valuable players. Therefore, while there is a positive correlation, it is not very high.\n",
    "\n",
    "- 'Goals': There is a positive correlation, and it is one of the highest among features. Players who score the most goals usually have higher market values. However, this correlation may vary for players in smaller teams who get more minutes and score goals, their overall market value might still depend on other stats or skills and especially on the league they're playing in.\n",
    "\n",
    "- 'highest_market_value_in_eur': High correlation with the target variable, this is due to the fact that many players might currently have their highest market value.\n",
    "\n",
    "- 'starting_count': Third highest correlation with the target variable, this is mainly due to the fact that players that start more matches, tend to be the best in their teams and therefore more valuable.\n",
    "\n",
    "- 'Premier League': There is a positive correlation. Over recent years, market values for players in the Premier League have tended to be higher compared to players in other leagues. This is due to factors like the Premier League’s intensity and competitiveness, the influence of the English press and PR, and the league’s financial capacity. Players with similar skills in other leagues might be evaluated differently because of these factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make scatterplots of some of the variables that are highly correlated with the dependent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_variables = ['highest_market_value_in_eur', 'Goals', 'Club Ranking', 'Age']\n",
    "\n",
    "def millions_formatter(x, pos):\n",
    "    return f'{x / 1e6:.1f}M' \n",
    "\n",
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "for i, var in enumerate(selected_variables):\n",
    "    plt.subplot(2, 2, i + 1) \n",
    "    sns.scatterplot(_datasetCleaning, x=selected_variables[i], y=target)\n",
    "    plt.title(f\"{var} vs {target}\")\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel(target)\n",
    "    plt.gca().yaxis.set_major_formatter(FuncFormatter(millions_formatter))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'highest_market_value_in_eur' : We notice a linear relationship with the target variable. As we mentioned before, this is due to the fact that many players market value is historically their highest, and often a player's market value is not very far from its highest. Exceptions to this occur when a player is very old, or their performances have consistently declined over a long period.\n",
    "\n",
    "- 'Goals': Most of the goal values are concentrated in the interval $[0, 5]$. Within this range, the market value is spread, indicating that scoring few goals does not always imply a specific market value. As the number of goals gets higher we tend to see higher market values.\n",
    "\n",
    "- 'Club Ranking': As discussed earlier, we generally observe higher market values for players in top teams (those with lower ranking numbers). However, there is a high density of players with lower market values playing for teams ranked in the top 200. Additionally, we observe some outliers in teams ranked extremely low (below 1000). These outliers are removed from the analysis to avoid distortion of results.\n",
    "\n",
    "- 'Age': The scatterplot displays a clear non linear pattern with a peak around a specific age range (likely in the early to mid 20s). This reflects players in their prime, when their physical abilities, experience, and skill sets are at their peak. Players aged below 23 generally have lower market values, with a few exceptions (likely exceptional talents or players with high potential). Young players are still developing their skills and gaining experience, which limits their immediate market value. Older players are perceived as having less long-term potential and reduced physical capabilities, leading to a sharp decline in market value. Some experienced top players may still retain relatively high market values, but they are very rare exceptions.\n",
    "\n",
    "We also notice some two outliers in terms of market value, which are the two current most expensive players. We decide to remove them before feeding the data to our models so that the performance doesn't get affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_datasetCleaning = _datasetCleaning[_datasetCleaning['Club Ranking'] < 1000]\n",
    "_datasetCleaning = _datasetCleaning[_datasetCleaning[target] < 125000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 'Premier League', which is a categorical variable (binary), we plot the two boxplots showing the market value (dependent variables) for players in the Premier League and players in the other four leagues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=_datasetCleaning['Premier League'], y=_datasetCleaning[target], color='lightblue')\n",
    "plt.title(f\"{target} Distribution by Age\")\n",
    "plt.xlabel('Premier League')\n",
    "plt.ylabel(target)\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(millions_formatter))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the median and, in particular, the 75th percentile of market value are significantly higher for players in the Premier League. This supports our earlier argument that players in the Premier League tend to achieve higher market values on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Feature transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the scatterplot of 'market_value_in_eur' vs 'Club Ranking', we notice a non linear relationship between the two variables.\n",
    "We denote the dependent variable as $y$ (market value) and the independent variable as $x$ (‘Club Ranking’), the relationship between the two can be approximated as $y \\propto \\frac{1}{x}$, with the points being densly concentrated under the curve $y = \\frac{1}{x}$. Furthermore, we notice that as the rankings approach 1 (top teams), the density of players with very high market values is not as high, and we still have a lot of players with low market value. Therefore, we can refine the approximation of the relationship and say that $y \\propto \\frac{1}{\\sqrt[4]{x}}$, with the points densely concentrated under this curve.\n",
    "\n",
    "Based on these findings, and in order to exploit this relationship, we apply a feature transformation to the variable $x$ (Club Ranking) by creating a new feature $f(x) = \\frac{1}{\\sqrt[4]{x}}$. This reciprocal fourth root feature mapping, is performed to capture the observed non-linear relationship between $x$ and the target variable $y$ (Market Value). The original variable $x$ is mapped to a new space where the relationship with $y$ becomes more linear and better aligns with the dense distribution of points under the curve $y = \\frac{1}{\\sqrt[4]{x}}$. This process is an example of feature mapping, which transforms features to enhance their relevance and improve the model’s ability to learn meaningful patterns. We call this new variable 'club_trans'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Club Ranking</th>\n",
       "      <th>Age</th>\n",
       "      <th>MP</th>\n",
       "      <th>Min</th>\n",
       "      <th>Goals</th>\n",
       "      <th>Shots</th>\n",
       "      <th>SoT</th>\n",
       "      <th>SoT%</th>\n",
       "      <th>G/Sh</th>\n",
       "      <th>G/SoT</th>\n",
       "      <th>...</th>\n",
       "      <th>Right Midfield</th>\n",
       "      <th>Right Winger</th>\n",
       "      <th>Right-Back</th>\n",
       "      <th>Second Striker</th>\n",
       "      <th>Bundesliga</th>\n",
       "      <th>La Liga</th>\n",
       "      <th>Ligue 1</th>\n",
       "      <th>Premier League</th>\n",
       "      <th>Serie A</th>\n",
       "      <th>club_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1596</td>\n",
       "      <td>1</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.28</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.264927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>475</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.35</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.214204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1799</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>1165</td>\n",
       "      <td>0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Club Ranking  Age  MP   Min  Goals  Shots   SoT  SoT%  G/Sh  G/SoT  ...  \\\n",
       "0           162   22  20  1596      1   1.53  0.28  18.5  0.04   0.20  ...   \n",
       "1           203   35  22  1980      0   0.86  0.05   5.3  0.00   0.00  ...   \n",
       "2           475   23  14   770      0   1.05  0.35  33.3  0.00   0.00  ...   \n",
       "3           199   22  20  1799      1   0.60  0.15  25.0  0.08   0.33  ...   \n",
       "4           382   30  15  1165      0   0.31  0.00   0.0  0.00   0.00  ...   \n",
       "\n",
       "   Right Midfield  Right Winger  Right-Back  Second Striker  Bundesliga  \\\n",
       "0               0             0           0               0           0   \n",
       "1               0             0           0               0           0   \n",
       "2               0             0           0               0           0   \n",
       "3               0             0           0               0           0   \n",
       "4               0             0           0               0           0   \n",
       "\n",
       "   La Liga  Ligue 1  Premier League  Serie A  club_trans  \n",
       "0        0        0               1        0    0.280299  \n",
       "1        0        1               0        0    0.264927  \n",
       "2        0        1               0        0    0.214204  \n",
       "3        0        1               0        0    0.266248  \n",
       "4        0        1               0        0    0.226196  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_datasetCleaning['club_trans'] = 1/np.power(_datasetCleaning['Club Ranking'], (1/4))\n",
    "_datasetCleaning.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show a scatterplot of the new variable vs market value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6)) \n",
    "sns.scatterplot(data=_datasetCleaning, x='club_trans', y=target)\n",
    "plt.title(f\"'club_trans vs {target}\")\n",
    "plt.xlabel('club_trans')\n",
    "plt.ylabel(target)\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(millions_formatter))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation of the new feature with the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4639918870297825\n"
     ]
    }
   ],
   "source": [
    "print(_datasetCleaning['club_trans'].corr(_datasetCleaning[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the relationship between the new variable and the target is more linear. Additionally, the correlation between the two is one of the highest, indicating that the transformation was effective in improving the relationship and capturing the underlying pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Club Ranking</th>\n",
       "      <th>Age</th>\n",
       "      <th>MP</th>\n",
       "      <th>Min</th>\n",
       "      <th>Goals</th>\n",
       "      <th>Shots</th>\n",
       "      <th>SoT</th>\n",
       "      <th>SoT%</th>\n",
       "      <th>G/Sh</th>\n",
       "      <th>G/SoT</th>\n",
       "      <th>...</th>\n",
       "      <th>Right Midfield</th>\n",
       "      <th>Right Winger</th>\n",
       "      <th>Right-Back</th>\n",
       "      <th>Second Striker</th>\n",
       "      <th>Bundesliga</th>\n",
       "      <th>La Liga</th>\n",
       "      <th>Ligue 1</th>\n",
       "      <th>Premier League</th>\n",
       "      <th>Serie A</th>\n",
       "      <th>club_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1596</td>\n",
       "      <td>1</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.28</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.264927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>475</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.35</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.214204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1799</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>1165</td>\n",
       "      <td>0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Club Ranking  Age  MP   Min  Goals  Shots   SoT  SoT%  G/Sh  G/SoT  ...  \\\n",
       "0           162   22  20  1596      1   1.53  0.28  18.5  0.04   0.20  ...   \n",
       "1           203   35  22  1980      0   0.86  0.05   5.3  0.00   0.00  ...   \n",
       "2           475   23  14   770      0   1.05  0.35  33.3  0.00   0.00  ...   \n",
       "3           199   22  20  1799      1   0.60  0.15  25.0  0.08   0.33  ...   \n",
       "4           382   30  15  1165      0   0.31  0.00   0.0  0.00   0.00  ...   \n",
       "\n",
       "   Right Midfield  Right Winger  Right-Back  Second Striker  Bundesliga  \\\n",
       "0               0             0           0               0           0   \n",
       "1               0             0           0               0           0   \n",
       "2               0             0           0               0           0   \n",
       "3               0             0           0               0           0   \n",
       "4               0             0           0               0           0   \n",
       "\n",
       "   La Liga  Ligue 1  Premier League  Serie A  club_trans  \n",
       "0        0        0               1        0    0.280299  \n",
       "1        0        1               0        0    0.264927  \n",
       "2        0        1               0        0    0.214204  \n",
       "3        0        1               0        0    0.266248  \n",
       "4        0        1               0        0    0.226196  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_datasetCleaning.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset in train and test, something classic. However, we choose to avoid using a valid set. The reason is the low number of entries (~1850)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = _datasetCleaning.drop(target, axis=1)\n",
    "Y = _datasetCleaning[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we make a pipeline that performs the scaling of our data, this is only using standard scaling. Then it optionally performs PCA and next trains the model.\n",
    "We use cross validation on the number of components of the PCA, and the option whether to use PCA or not and on the parameters of our models to evaluate. We perform the selection based on the mean squared error metric. \n",
    "We evaluate seven models with different combination of parameters for the model and for the PCA and we choose the most performing one. These are the evaluated models and their parameters:\n",
    "\n",
    "- Linear Regression: {\"model__fit_intercept\": [True, False]}\n",
    "\n",
    "- Ridge Regression: {\"model__alpha\": [0.1, 1.0, 10.0]}\n",
    "\n",
    "- Lasso Regression : {\"model__alpha\": [0.01, 0.1, 1.0]}\n",
    "\n",
    "- ElasticNet: (ElasticNet(), {\"model__alpha\": [0.01, 0.1, 1.0], \"model__l1_ratio\": [0.3, 0.5, 0.7]}),\n",
    "\n",
    "- Decision Tree: {\"model__max_depth\": [3, 5, 10], \"model__min_samples_split\": [2, 5, 10]}\n",
    "\n",
    "- Random Forest: {\"model__n_estimators\": [50, 100, 200], \"model__max_depth\": [3, 5, 10]}\n",
    "\n",
    "- Gradient Boosting: {\"model__n_estimators\": [50, 100, 200], \"model__learning_rate\": [0.01, 0.1, 0.2], \"model__max_depth\": [3, 5]}\n",
    "\n",
    "For PCA, we check for the following numbers of components [None, 5, 10, 25, 50, 100].\n",
    "\n",
    "We include none to include skipping PCA as an option, but setting 'n_components' = None still performs PCA. In order to solve this issue, we build our parameter list for PCA such that when the value is null it passes a FunctionTransformer, which is an object that tranforms the data according to a chosen function. To skip PCA we assign this object with the identity function as input, which leaves the data unchanged and therefore skips the PCA step. In the other cases (n_components not null), the parameter list gives the PCA object with the corresponding number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n",
      "Linear Regression\n",
      "Best Params: {'model__fit_intercept': True, 'pca': PCA(n_components=100)}\n",
      "Best CV Score (MSE): 82302361983446.78\n",
      "Best CV Score (R^2): 0.6841\n",
      "\n",
      "Training Ridge Regression...\n",
      "Ridge Regression\n",
      "Best Params: {'model__alpha': 10.0, 'pca': PCA(n_components=100)}\n",
      "Best CV Score (MSE): 81483337256528.73\n",
      "Best CV Score (R^2): 0.6873\n",
      "\n",
      "Training Lasso Regression...\n",
      "Lasso Regression\n",
      "Best Params: {'model__alpha': 0.01, 'pca': PCA(n_components=100)}\n",
      "Best CV Score (MSE): 82303407985434.45\n",
      "Best CV Score (R^2): 0.6841\n",
      "\n",
      "Training ElasticNet...\n",
      "ElasticNet\n",
      "Best Params: {'model__alpha': 0.1, 'model__l1_ratio': 0.3, 'pca': PCA(n_components=100)}\n",
      "Best CV Score (MSE): 78731118588313.09\n",
      "Best CV Score (R^2): 0.6983\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree\n",
      "Best Params: {'model__max_depth': 5, 'model__min_samples_split': 10, 'pca': FunctionTransformer(func=<function <listcomp>.<lambda> at 0x00000000649829D0>)}\n",
      "Best CV Score (MSE): 76748836366792.31\n",
      "Best CV Score (R^2): 0.7030\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest\n",
      "Best Params: {'model__max_depth': 10, 'model__n_estimators': 100, 'pca': FunctionTransformer(func=<function <listcomp>.<lambda> at 0x00000000649828B0>)}\n",
      "Best CV Score (MSE): 44635061426508.73\n",
      "Best CV Score (R^2): 0.8278\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting\n",
      "Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'pca': FunctionTransformer(func=<function <listcomp>.<lambda> at 0x0000000064982B80>)}\n",
      "Best CV Score (MSE): 38480240038045.77\n",
      "Best CV Score (R^2): 0.8526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": (LinearRegression(), {\"model__fit_intercept\": [True, False]}),\n",
    "    \"Ridge Regression\": (Ridge(), {\"model__alpha\": [0.1, 1.0, 10.0]}),\n",
    "    \"Lasso Regression\": (Lasso(), {\"model__alpha\": [0.01, 0.1, 1.0]}),\n",
    "    \"ElasticNet\": (ElasticNet(), {\"model__alpha\": [0.01, 0.1, 1.0], \"model__l1_ratio\": [0.3, 0.5, 0.7]}),\n",
    "    \"Decision Tree\": (DecisionTreeRegressor(), {\"model__max_depth\": [3, 5, 10], \"model__min_samples_split\": [2, 5, 10]}),\n",
    "    \"Random Forest\": (RandomForestRegressor(random_state=42), {\"model__n_estimators\": [50, 100], \"model__max_depth\": [3, 5, 10]}),\n",
    "    \"Gradient Boosting\": (GradientBoostingRegressor(random_state=42), {\"model__n_estimators\": [50, 100], \"model__learning_rate\": [0.01, 0.1, 0.2], \"model__max_depth\": [3, 5]})\n",
    "}\n",
    "\n",
    "environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "best_model_name = None\n",
    "best_model = None\n",
    "best_score = 0\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Create the pipeline with standard scaler, PCA (optional), and the model\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA()),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    # Add PCA-related hyperparameters to the grid search\n",
    "    pca_options = [None, 5, 25, 50, 100]  # No PCA (None) and PCA options\n",
    "    pca_param = {\"pca\": [PCA(n_components=n) if n else FunctionTransformer(lambda x: x) for n in pca_options]}  # Identity transformer for no PCA\n",
    "    full_params = {**params, **pca_param}\n",
    "    \n",
    "    # Perform GridSearchCV\n",
    "    grid = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid=full_params, \n",
    "        cv=5, \n",
    "        scoring={'MSE': 'neg_mean_squared_error', 'R2': 'r2'}, \n",
    "        refit='MSE',  \n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model_current = grid.best_estimator_\n",
    "    best_cv_mse = -grid.cv_results_['mean_test_MSE'][grid.best_index_] \n",
    "    best_cv_r2 = grid.cv_results_['mean_test_R2'][grid.best_index_]\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        \"Best Params\": grid.best_params_,\n",
    "        \"Best CV Score (MSE)\": best_cv_mse,\n",
    "        \"Best CV Score (R^2)\": best_cv_r2,\n",
    "        \"Best Model\": best_model_current\n",
    "    }\n",
    "\n",
    "    print(f\"{name}\")\n",
    "    print(f\"Best Params: {grid.best_params_}\")\n",
    "    print(f\"Best CV Score (MSE): {best_cv_mse:.2f}\")\n",
    "    print(f\"Best CV Score (R^2): {best_cv_r2:.4f}\\n\")\n",
    "\n",
    "    if best_score < best_cv_r2:\n",
    "        best_score = best_cv_r2\n",
    "        best_model_name = name\n",
    "        best_model = best_model_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = list(results.keys())\n",
    "r2_scores = [results[name][\"Best CV Score (R^2)\"] for name in model_names]\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, r2_scores, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Best R² Score')\n",
    "plt.title('Comparison of Best R² Scores Across Models')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model is Gradient Boosting, with the lowest mean square error with a substantial gap from other models, and with the highst R squared value.\n",
    "\n",
    "We notice that the best performing pipeline does not use PCA. We list the best combination of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__learning_rate': 0.1,\n",
       " 'model__max_depth': 3,\n",
       " 'model__n_estimators': 100,\n",
       " 'pca': FunctionTransformer(func=<function <lambda> at 0x1317c8400>)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[best_model_name]['Best Params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Prediction on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the best model we got to predict the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score MSE: 36898005546138\n",
      "Test Score MAE: 3600359\n",
      "Test Score R^2: 0.8788\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test Score MSE: {mse:.0f}\")\n",
    "print(f\"Test Score MAE: {mae:.0f}\")\n",
    "print(f\"Test Score R^2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the performance of our model on the test set is almost the same as in the validation set, which means our model generalizes well on unseen data and doesn't overfit on the training set.\n",
    "\n",
    "The Mean Absolute Error gives us an idea of the error made on average by our model in predicting the market value. This error is pretty low considering that the market value can get up to $200m for some players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 - Confidence Interval for the Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give further information about our mean absolute error, which represents the average error on a prediction, we try to give a confidence interval.\n",
    "\n",
    "We can notice that this metric is the mean of multiple observations of a random variable (the error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_test)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 386 instances of errors, assumed to be independent and identically distributed (the errors are derived from repeated predictions of the same model on comparable data, with no indication of systematic variation across instances), which is enough to use the Central Limit Theorem, which allows us to state that MAE tends to follow a normal distribution, $\\text{MAE} \\sim \\mathcal{N}(\\mu, \\sigma^2)$, where $\\mu$ and $\\sigma^2$ are unknown parameters of the population.\n",
    "\n",
    "Since our parameters are unknown, we use their following empirical estimates:\n",
    "\n",
    "- For $\\mu$ we use the sample mean $\\bar{x} = \\dfrac{1}{n} \\sum_{i = 1}^{n} x_i$.\n",
    "\n",
    "- For $\\sigma^2$ we use the estimate $s^2 = \\dfrac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar x)^2$\n",
    "\n",
    "Now we have to build the confidence interval. In order to do so we mention that the variable $\\dfrac{\\bar x-\\mu}{\\sqrt{\\dfrac{s^2}n}}$ follows a Student's t-distribution with $n - 1$ degrees of freedom.\n",
    "\n",
    "Therefore we can compute the confidence integral as follows: \n",
    "$CI = \\bar{x} \\pm t_{n-1, 1 - \\frac{\\alpha}{2}} \\dfrac{s}{\\sqrt{n}}$ for $(1 - \\alpha)$% confidence.\n",
    "\n",
    "Now everything is set, and we can compute the 95% confidence interval for our MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: [3110123, 4090596]\n"
     ]
    }
   ],
   "source": [
    "def compute_confidence_interval(data, alpha=0.05):\n",
    "    n = len(data)\n",
    "    sample_mean = np.mean(data)\n",
    "    sample_std = np.std(data, ddof=1) # ddof stands for degrees of freedom, we use it to divide by n-1 instead of n\n",
    "    standard_error = sample_std / np.sqrt(n)\n",
    "    \n",
    "    t_critical = t.ppf(1 - alpha/2, df=n-1)\n",
    "    margin_of_error = t_critical * standard_error\n",
    "    \n",
    "    # Confidence interval\n",
    "    lower_bound = sample_mean - margin_of_error\n",
    "    upper_bound = sample_mean + margin_of_error\n",
    "    \n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "abs_errors = np.abs(y_test - y_pred)\n",
    "lower, upper = compute_confidence_interval(abs_errors, 0.05)\n",
    "print(f\"Confidence Interval: [{lower:.0f}, {upper:.0f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are 95% confident that the true mean absolute error (MAE) lies within the interval $[3.1\\text{m}, 4.1\\text{m}]$. This means that the average prediction error for the market value of football players is estimated to fall between €3.1 million and €4.1 million.\n",
    "\n",
    "The confidence interval provides valuable information about the range of possible values for the true MAE, reflecting the uncertainty in the estimate based on the sample data.\n",
    "\n",
    "Given that the market values of football players can go as high as €125 million, this range of error represents a small proportion of the highest market values. However, its acceptability should be evaluated relative to the distribution of market values across all players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 - Relative Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section, we have provided information about the MAE, which is a metric giving an idea about the average error for each prediction, therefore the performance of our model on average.\n",
    "\n",
    "Now, we would like to know where our model performs well and where it has difficulties. Our first intuition is that the model might struggle to predict points with market value very close to zero due to the high range for the dependent variable.\n",
    "\n",
    "In order to inspect this, we compute the relative errors to each prediction. The relative error is a measure of the accuracy of a prediction, expressed as the ratio of the absolute error to the true value:\n",
    "\n",
    "$$\\text{Relative Error} = \\frac{\\text{Absolute Error}}{\\text{True Market Value}}$$\n",
    "\n",
    "It quantifies the error as a proportion of the true value, providing insight into the significance of the error relative to the size of what is being measured. In the context of predicting football players’ market values, relative error is particularly useful because the market values span a wide range, from very low to very high. While absolute errors might appear large for high-value players, their impact is smaller relative to the player’s true value. By examining relative error, we can assess the proportional accuracy of the model across different ranges of market values, ensuring fair evaluation and identifying where the model performs well or struggles.\n",
    "\n",
    "Next, we compute the relative errors and we visualise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_errors = abs_errors / y_test\n",
    "\n",
    "# Create the subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharex=True)\n",
    "\n",
    "# Without logarithmic scale\n",
    "axes[0].scatter(y_test, relative_errors, alpha=0.7)\n",
    "axes[0].axhline(y=0, color='gray', linestyle='--', linewidth=1)\n",
    "axes[0].set_title('Relative Errors vs. True Market Values (Linear Scale)')\n",
    "axes[0].set_xlabel('True Market Value (in millions)')\n",
    "axes[0].set_ylabel('Relative Error')\n",
    "axes[0].grid(True)\n",
    "axes[0].xaxis.set_major_formatter(FuncFormatter(millions_formatter))\n",
    "\n",
    "# With logarithmic scale\n",
    "axes[1].scatter(y_test, relative_errors, alpha=0.7)\n",
    "axes[1].axhline(y=0, color='gray', linestyle='--', linewidth=1)\n",
    "axes[1].set_title('Relative Errors vs. True Market Values (Logarithmic Scale)')\n",
    "axes[1].set_xlabel('True Market Value (in millions)')\n",
    "axes[1].set_ylabel('Relative Error (Log Scale)')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_ylim(10e-4, None) \n",
    "axes[1].grid(True)\n",
    "axes[1].xaxis.set_major_formatter(FuncFormatter(millions_formatter))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first plot, we observe that for some players with very small market values close to zero, the relative error is high, indicating poor predictions for these cases. However, this is expected given the wide range of market values our model is designed to predict. For players with high market values, the model performs well, and the predictions are relatively more precise.\n",
    "\n",
    "In the second plot, which uses a logarithmic scale to better visualize the relative errors, we see that for most players with small market values, the model achieves a relative error lower than one. This indicates good predictions for players in this range. However, as market values decrease further, we notice an increase in the relative error for some players. This behavior is expected due to the broad range of market values in the dataset, making predictions for very low market values more challenging."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
